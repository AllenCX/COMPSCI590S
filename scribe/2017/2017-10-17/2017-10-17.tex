\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\usepackage{graphicx}
\usepackage{url}

%
% The following commands sets up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}
\newcommand{\dnl}{\mbox{}\par}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
	\pagestyle{myheadings}
	\thispagestyle{plain}
	\newpage
	\setcounter{lecnum}{#1}
	\setcounter{page}{1}
	\noindent
	\begin{center}
		\framebox{
			\vbox{\vspace{2mm}
				\hbox to 6.28in { {\bf COMPSCI~590S~~~Systems for Data Science
						\hfill Fall 2017} }
				\vspace{4mm}
				\hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
				\vspace{2mm}
				\hbox to 6.28in { {\it Lecturer: #3 \hfill Scribe(s): #4} }
				\vspace{2mm}}
		}
	\end{center}
	\markboth{Lecture {#1}: #2}{Lecture {#1}: #2}
	\vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
%
\renewcommand{\cite}[1]{[#1]}

% \input{epsf}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{FIGURE-SIZE}{CAPTION}{FILENAME}
\newcommand{\fig}[4]{
	\vspace{0.2 in}
	\setlength{\epsfxsize}{#2}
	\centerline{\epsfbox{#4}}
	\begin{center}
		Figure \thelecnum.#1:~#3
	\end{center}
}

% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% Some useful equation alignment commands, borrowed from TeX
\makeatletter
\def\eqalign#1{\,\vcenter{\openup\jot\m@th
		\ialign{\strut\hfil$\displaystyle{##}$&$\displaystyle{{}##}$\hfil
			\crcr#1\crcr}}\,}
\def\eqalignno#1{\displ@y \tabskip\@centering
	\halign to\displaywidth{\hfil$\displaystyle{##}$\tabskip\z@skip
		&$\displaystyle{{}##}$\hfil\tabskip\@centering
		&\llap{$##$}\tabskip\z@skip\crcr
		#1\crcr}}
\def\leqalignno#1{\displ@y \tabskip\@centering
	\halign to\displaywidth{\hfil$\displaystyle{##}$\tabskip\z@skip
		&$\displaystyle{{}##}$\hfil\tabskip\@centering
		&\kern-\displaywidth\rlap{$##$}\tabskip\displaywidth\crcr
		#1\crcr}}
\makeatother

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:



% Some general latex examples and examples making use of the
% macros follow.

\begin{document}
	
	%FILL IN THE RIGHT INFO.
	%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
	\lecture{11}{Garbage Collection and File Systems}{Emery Berger}{Benjamin Cheung, Rohit Narasimhan}
	
	\section{Garbage Collection}
	
	In the previous class, we discussed the concept of Garbage Collection and two major techniques for GC. 
	\begin{enumerate}
		\item We discussed Reference Counting which is an incomplete algorithm due to the presence of cycles.
		\item Alternatively, we can use Mark and Sweep to fill in holes. It marks from the roots to the extent that can be reached and then sweeps away the nodes that are unreachable.
	\end{enumerate} 
	\subsection{Semi-Space}
	Semi-Space garbage collection (also called Copying or Relocating GC) is an algorithm which works on the concept of dividing all memory into two chunks - a \lq from-space\rq \, and a \lq to-space\rq .
	\begin{itemize}
		\item Place all active memory into the from-space.
		\item Use bump pointing to know the area of memory that you insert into.
		\item When the pointer reaches the end i.e. there is insufficient space to fulfill an allocation, the garbage collection starts.
		\item We define a \lq live\rq \, memory object as one that has a pointer to it from some other memory object.
		\item Iterate through the current from-space and move all live memory objects to the to-space.
		\item All items left in the from-space are not alive and can be removed. The to-space and the from-space then switch roles.
	\end{itemize}
	Thus, a collection consists of swapping the roles of the regions, and copying the live objects from from-space to to-space, leaving a block of free space (corresponding to the memory used by all unreachable objects) at the end of the to-space. Since objects are moved during a collection, the addresses of all references must be updated. This is done by storing a \lq forwarding-address\rq \, for an object when it is copied out of from-space.
	
	{\large Problems}
	\begin{itemize}
		\item The actual memory space is halved. You would need 2X the memory to do the same things. In Mark Sweep, we don't lose the amount of available memory.
		\item Copying your memory over to the new space takes time and costs CPU cycles.
		\item After copying, you get Cache Thrashing i.e. everything currently in cache space is a miss to all the new copied memory.
	\end{itemize}
	
	{\large Benefits}
	\begin{itemize}
		\item Implicitly compacting the heap. Fragmentation is avoided.
		\item Allocation costs are extremely low as there is no need to maintain and search lists of free memory
		\item Locality is high.
	\end{itemize}
	
	\subsection{Stop-the-world}
	\begin{itemize}
		\item Some GC algorithms employ a mechanism called \lq Stop-the-world\rq.
		\item Stop-the-world garbage collectors completely halt the execution of the program when GC is running and this lasts till the collection is completed.
		\item This is a reasonably elegant algorithm with simple allocation.
		\item The major disadvantage is that the program can perform no useful work while a collection cycle is running. It also leads to a slowdown due to the associated cache warm up.
	\end{itemize}
	
	\subsection{Mark-Sweep Compact}
	\begin{itemize}
		\item One of the challenges of the Mark-and-Sweep algorithm was the need for manual compaction. 
		\item On the other hand, in semi-space garbage collectors, the compaction was implicitly achieved by simply laying the objects out in a row.
		\item Mark-Sweep compaction walks through and compacts after performing GC.
		\item Thus explicit compaction was still required. It was also much more challenging to code and required complicated fix-up.
	\end{itemize}
	
	\subsection{Generational Garbage Collection}
	The background for Generational GC comes from \lq Self\rq \, - an object-oriented programming language created by David Ungar and Craig Chambers, in which everything is an object! This led to innovations in dynamic compilation through JIT as well as garbage collection. We would typically need to allocate a heap size which is 3-5 times what the program needs and this over-provisioning is necessary for performance.
	Generational GCs operate on the underlying concept that most objects die young, also called the generational hypothesis.
	
	{\large Working}
	\begin{itemize}
		\item New objects are spawned, but placed in a separate buffer area called a nursery.
		\item Objects are expected to die young and not make it in the nursery. The survivors are copied out into a next generation buffer.
		\item There are immortal objects as well that live longer than what is ideal. These are never GC'd. Objects that are speculated to be immortal are \lq pretenured \rq.
		\item The objects in the older generation that may reference objects in new space are kept in a \lq remembered set\rq.
		\item The code that gets executed after pointer updates is called a a write barrier which ensures that generational invariants are maintained.
	\end{itemize}
	
	In Java, you can specify the number of generations. However, more number of generations can be bad because it has to copy more stuff out. \newline Generational GCs do not work with Big Data. As objects need to die young, it doesn't work with MapReduce. When you map, a lot of objects are produced after each parallel map phase. In the reduce phase, the objects would finally not be used and thus can be cleared by GC. This breaks the notion of objects dying young.
	
	\subsection{Concurrent and Incremental GC}
	\begin{itemize}
		\item Incremental and Concurrent garbage collectors do not require a \lq stop-the-world\rq \, when the collector is running.
		\item Incremental garbage collectors perform the garbage collection cycle in discrete phases, with program execution permitted between each phase (and sometimes during some phases).
		\item Concurrent garbage collectors are incremental collectors which perform collection in parallel with the program execution. 
	\end{itemize}
	
	\section{File Systems}
	\subsection{Traditional File Systems}
	File Systems have stood the test of time. The traditional file system has a hierarchical structure and a directory tree as the file system layout.
	Apple's Mac OS was one of the first to have such a file system called the Hierarchical File System (HFS). Most traditional file systems have a POSIX abstraction layer which functins like an API layer. This API is quite narrow meaning you cannot do too much with a file system. Some of the functions allowed using this API layer include :
	\begin{itemize}
		\item create()
		\item open()
		\item close()
		\item read()
		\item write()
	\end{itemize}
	Some of the popular file systems are : ext3, ext4, HFS, XFS, NTFS, ReiserFS, FAT32, and ZFS
	\subsection{Network File System}
	A network file system is a file system that acts as a client for a remote file access protocol, providing access to files on a server. Programs using local interfaces can transparently create, manage and access hierarchical directories and files in remote network-connected computers.
	\subsection{Google File System}
	\begin{itemize}
		\item Scalable distributed file system for large distributed data-intensive applications.
		\item Provides fault-tolerance
		\item Presents unified view of the world to API.
		\item Consists of a single master and multiple chunkservers.
		\item Files broken into 64MB chunks
		\item For reliability, each chunk is replicated on multiple chunkservers.
		\item The large chunk size offers several advantages. Also, considering the huge size of the data, having small 4KB blocks doesn't make much sense. 
	\end{itemize}
	
\end{document}